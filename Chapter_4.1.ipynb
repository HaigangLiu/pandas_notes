{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "The ndarray needs to interpret a chunk of memory as a particular type of data, hence the data type. We can \n",
    "\n",
    "(1) assign type information when creating an array;\n",
    "\n",
    "(2) cast an existing array into a different type. You will, understandably, get an error by trying to cast some English letter to integers.\n",
    "\n",
    "(3) use the python built in data type, int and float*\n",
    "\n",
    "(4) more often than not python can infer things just fine.\n",
    "\n",
    "This is because Python actually used a standard double precision floating point type, which is exactly np.float64. Similarly, numpy will understand int as numpy.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 float64\n",
      "[b'1' b'2' b'3' b'4' b'5']\n",
      "|S12\n",
      "[b'1' b'2' b'3' b'4' b'5']\n",
      "|S11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "case_1 = np.array([1,2,3,4,5], dtype=np.int32) #specifying types\n",
    "case_1_float = np.array([1,2,3,4,5], dtype=np.float64) # a different type\n",
    "print(case_1.dtype, case_1_float.dtype)\n",
    "\n",
    "cast_ = case_1.astype('S12') # a string of length 10. Longer than that will be truncated\n",
    "print(cast_)\n",
    "print(cast_.dtype)\n",
    "\n",
    "cast_ = case_1.astype(np.string_)# a similar way to cast array to string type\n",
    "print(cast_)\n",
    "print(cast_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "<U2\n"
     ]
    }
   ],
   "source": [
    "case_3 = np.array([1,2,3,3,4], dtype=int)\n",
    "print(case_3.dtype)\n",
    "\n",
    "case_4 = np.array(['12', '23'])\n",
    "print(case_4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things to notice here:\n",
    "\n",
    "(1) 'U' means unicode string and 2 indicates the length of data. Note that the aforementioned  S10 gives a byte string but U gives a unicode string. In other words, we got to decode the np.string_ into utf-8 to get a python string. \n",
    "\n",
    "(2) whenver we call astype(), a copy is made! To further showcase the point, use the flags attribute, see below.\n",
    "\n",
    "(3) however we do slicing, a view (more like a reference, will be generated--pay attention to the OWNDATA attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : False\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_[0:2].flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "There are several ways of doing slicing, some of which seem similar, but have pretty different behaviors, especially when it comes down to copy vs. view argument. Conclusion first: basic indexing and slicing gives view, boolean and fancy indexing (use a list to do indexing) gives copy. Let's show them one by one with a two-d array. Last but not least, you use any combination of them, but it will end up as a copy as long as one of last two methods are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.random.randn(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "basic_indexing = test_array[3]\n",
    "print(basic_indexing.flags.owndata) #copy or not\n",
    "print(basic_indexing.copy().flags.owndata) #make a copy and it's gonna be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "basic_slicing = test_array[1:3,:]\n",
    "print(basic_slicing.flags.owndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "mask = [True]* 5 + [False]*5 #take first half and discard the rest\n",
    "boolean_indexing = test_array[mask]\n",
    "print(boolean_indexing.flags.owndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "integer_mask = np.random.choice(np.arange(10), 10)\n",
    "fancy_indexing = test_array[integer_mask]\n",
    "print(fancy_indexing.flags.owndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author of Python for Data Analysis claims that boolean selection will not fail even if the boolean array is not the correct length, it's not true.\n",
    "\n",
    "Here's more caveats:\n",
    "\n",
    "(1) The .copy() function is always going to work, and with this method you can create copy even if it is indexing or slicing. \n",
    "\n",
    "(2) slicing/indexing allows us to set value. Generally speaking, we can either pass in the new data of rigth size, or just pass a scalar and let numpy figure it out. However, numpy wont let the wrong dimension slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.        , 10.        ],\n",
       "       [-1.23205384, -0.53359214],\n",
       "       [-0.57203771, -1.00385177],\n",
       "       [ 0.06078447,  1.08760236],\n",
       "       [-0.92981901,  0.05753419],\n",
       "       [ 0.82754667,  0.12812708],\n",
       "       [-0.04529814,  0.22594587],\n",
       "       [-0.58298997, -1.44182617],\n",
       "       [-0.86815463, -1.01110198],\n",
       "       [ 1.65811791,  1.3490869 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting_data_with_scalar = np.random.randn(10, 2)\n",
    "setting_data_with_scalar[0, :] = 10\n",
    "setting_data_with_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.        , 10.        ],\n",
       "       [-0.99661862, -0.03248761],\n",
       "       [-1.46269561,  0.10846294],\n",
       "       [ 0.29109391,  0.58900529],\n",
       "       [ 0.30499742,  0.05051971],\n",
       "       [ 1.35256148, -1.45365382],\n",
       "       [-0.24992649,  3.42659455],\n",
       "       [ 0.83801317, -0.68639557],\n",
       "       [ 2.3285309 ,  2.55200234],\n",
       "       [ 0.80087307, -0.28647745]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting_data_with_array = np.random.randn(10, 2)\n",
    "setting_data_with_array[0, :] = [10, 10] # this is fine \n",
    "setting_data_with_array[0, :] = np.array([10, 10]) # this is also ok\n",
    "#setting_data_with_array[0, :] = [10, 10, 10] # will get a value error\n",
    "setting_data_with_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there are three operators are kind of both important and annoying. ~ means negating, and can help us convert True to False or vice versa. This is a super useful tool but cannot be used for native python lists but only works for numpy arrays.\n",
    "\n",
    "Secondly, the \"and\" and \"or\" operators are & and |. This is fine but you cannnot use these two english words directly. And since pandas as built on numpy, the same annoyance is inherited. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape and reshape\n",
    "\n",
    "Here's something obvious:\n",
    "\n",
    "1. To get a shape of an array, use .shape attribute\n",
    "2. To get number of dimensions of an array, use ndim attribute\n",
    "3. To reshape the array use .reshape() method. It'll generate a view\n",
    "\n",
    "However there is something more than what meets the eye in reshape. Think about reshape a list of numbers into a squared matrix. Should you got row first or column first? This actually leads to a major argument of C order and Fortran order. And this has something to do which two floating numbers are adjacent in the memory, and thus makes a performance difference when it comes to aggregation operation. But we'll discuss that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10, 15, 20],\n",
       "       [ 1,  6, 11, 16, 21],\n",
       "       [ 2,  7, 12, 17, 22],\n",
       "       [ 3,  8, 13, 18, 23],\n",
       "       [ 4,  9, 14, 19, 24]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(25).reshape((5,5), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(25).reshape((5,5), order='C') # by row is a defalt option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 10 15 20  1  6 11 16 21  2  7 12 17 22  3  8 13 18 23  4  9 14 19\n",
      " 24]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n"
     ]
    }
   ],
   "source": [
    "# when we want to get a list from a matrix\n",
    "# this kind of decision is still relevant\n",
    "square_matrix = np.arange(25).reshape(5,5)\n",
    "print(square_matrix.ravel(order='F'))\n",
    "print(square_matrix.ravel(order='C'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing, there's actually two function in numpy doing the same thing, ravel() and flatten(), both are straightening a matrix in a list. The only difference is the latter is creating a copy but the former is a view. Here's the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "square_matrix2 = np.arange(25).reshape(5,5)\n",
    "view_ = square_matrix.ravel('C')\n",
    "copy_ = square_matrix.flatten('C')\n",
    "print(view_.flags.owndata) # not copy from ravel\n",
    "print(copy_.flags.owndata) # copy from ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's elaborate the difference of c order and fortran order and its effect on performance. C order traverses high dimension first and Fortran traverses low dimmensions first. Here's a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(9).reshape(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember that axis 0 is row and axis 1 is column? if we go by C order, we'll visit 0 first and then 1 and then 2, which means we are traversing axis 1 first before we jump to next line. However, fortran order is the opposite, we have to go 0, 3, 6, which means we have to advance on axis 0 before we advancing on axis 1. \n",
    "\n",
    "Another way to understand this is C order goes like [0,1], [0,2], [0,3] before the first dimension jumps to 1. And fortran order goes like [0,1], [1,1], [2,1] and etc.\n",
    "\n",
    "The whole reason behind this is the data is stored in the memory in a linear matter but we need to organise it in a matrix form and thus we got to make a choice. \n",
    "\n",
    "This choice means in the C order layout, row observations are closer to each other hence row operations are faster and for fortran column operations are faster. We can easily showcase this for a large dataset, and this is usually one of the directions to squeeze some performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_c_order = np.random.randn(1000000).reshape((1000, 1000),order='C')\n",
    "the_fortran_order = np.random.randn(1000000).reshape((1000, 1000), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716 µs ± 47.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "c = the_c_order.mean(axis=0) # get the col sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 µs ± 9.52 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f = the_fortran_order.mean(axis=0) #get the col sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: we aggregate on column (along axis 0), and that's how fortran order organizes data. It can double the speed! However, after slicing, it's possible that we end up with a data array that is neither C contiguous or Fortran contiguous."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
