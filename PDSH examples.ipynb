{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Bike counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial cleaning ups\n",
    "\n",
    "Several highlights here. parse_dates can be used to parse dates based on the info of a particular column. Index_col can be used to build a index column. We end up with integer index if that is not specified.\n",
    "\n",
    "The next thing we do is to add a column called total based on daily summation. And there's two major ways to do it: 1. get the two columns and sum them up. 2. Use query like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#parse_dates specify which columns to read date from\n",
    "bike_data = pd.read_csv('bikes.csv', parse_dates=['Date'], index_col='Date')\n",
    "bike_data.columns = ['east', 'west']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.head()\n",
    "#get the totoal\n",
    "bike_data_copy = bike_data.copy()\n",
    "bike_data_copy.eval('total=east+west', inplace=True)\n",
    "bike_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data['total'] = bike_data['east'] + bike_data['west']\n",
    "bike_data.dropna(inplace=True)\n",
    "bike_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bike_data.plot() #for each column generate a line...not so informative here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sum = bike_data_copy.resample('W').sum() # time stamp has to be (part) in index.\n",
    "weekly_sum.plot(style=[':', '--','-']) #sum of each week... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = bike_data.resample('D').sum()\n",
    "daily_data.rolling(30, center=True).sum().plot(style=[':', '-', '--']) #center means 15 days on each side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarly we can use gaussian kernel to smooth it\n",
    "#bigger std is going to make graphs smoother\n",
    "daily_data.rolling(50, win_type='gaussian').sum(std=100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupy time of the day... \n",
    "#for pd.to_datetime.. the series will have a date and time attribute!\n",
    "by_hour = bike_data.groupby(bike_data.index.time).mean()\n",
    "by_hour.plot(style=['-',':','--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarly we can groupby week and days..\n",
    "bike_data.groupby(bike_data.index.dayofweek).mean().plot(style=['-',':','--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "weekdays = bike_data.loc[bike_data.index.dayofweek < 5]\n",
    "weekend = bike_data.loc[bike_data.index.dayofweek >= 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "f, axes = plt.subplots(1,2, figsize=[10,3])\n",
    "\n",
    "weekdays.groupby(weekdays.index.time).mean().plot(ax=axes[0])\n",
    "axes[0].set_title('weekdays')\n",
    "weekend.groupby(weekend.index.time).mean().plot(ax=axes[1])\n",
    "axes[1].set_title('weekend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resample is a data aggregation operation and asfreq is a data selection which keeps the last value by default. Here's a comparison with the bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "east_ts = bike_data.east\n",
    "one_month = east_ts['2012-10-03':'2012-11-03']\n",
    "f, ax = plt.subplots(1,1)\n",
    "one_month.resample('w').mean().plot(ax=ax)\n",
    "one_month.asfreq(freq='W').plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above graph looks bizzar because the asfreq function takes the last value of a period, which is an hourly count. But the resample('w').mean() gives the mean value of that week. Note that the last hour of a day has to be around midnight and that explains the low number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('weather.csv')\n",
    "weather['DATE'] = pd.to_datetime(weather.DATE, format='%Y%m%d')\n",
    "weather = weather[(weather.DATE >= '2012-01-01') & (weather.DATE <= '2014-12-31')]\n",
    "weather['dry'] = (weather.PRCP>0).astype(int)\n",
    "weather['TMIN'] = weather['TMIN']/10\n",
    "weather['TMAX'] = weather['TMAX']/10\n",
    "weather['temp'] = 0.5*(weather['TMIN'] + weather['TMAX'] )\n",
    "weather = weather[['temp', 'DATE', 'dry', 'PRCP']]\n",
    "\n",
    "daily_total = bike_data.resample('D').sum()['total']\n",
    "daily_total = daily_total.loc['2012':'2014']\n",
    "\n",
    "X = pd.get_dummies(daily_total.index.dayofweek)\n",
    "X.columns = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "X.index = daily_total.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar #generate a list of holidays\n",
    "holiday_indicator = pd.Series(1, index=USFederalHolidayCalendar().holidays('2012', '2014'))\n",
    "holiday_indicator = holiday_indicator.to_frame()\n",
    "holiday_indicator.columns = ['holiday']\n",
    "\n",
    "X = pd.merge(X, holiday_indicator, left_index=True, right_index=True, how='left')\n",
    "X.loc[X.holiday.isnull(), 'holiday'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hours_of_daylight(date, axis=23.44, latitude=47.61): \n",
    "    days = (date - pd.datetime(2000, 12, 21)).days\n",
    "    m = (1. - np.tan(np.radians(latitude))* np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25))) \n",
    "    return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "X['daylight_hrs'] = list(map(hours_of_daylight, X.index))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.merge(X, weather, left_index=True, right_on='DATE', how='left')\n",
    "X_combined.reset_index(drop=True)\n",
    "X_combined = X_combined.set_index(['DATE'])\n",
    "X_combined['annual'] = (X_combined.index - X_combined.index[0]).days/365\n",
    "X_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "m = LinearRegression(fit_intercept=False)\n",
    "m.fit(X_combined, daily_total.values)\n",
    "plt.plot(m.predict(X_combined), alpha=0.3)\n",
    "plt.plot(daily_total.values, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "m = LinearRegression(fit_intercept=False)\n",
    "result_recorder = []\n",
    "for i in range(1000):\n",
    "    v = m.fit(*resample(X_combined, daily_total.values)).coef_\n",
    "    result_recorder.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values = pd.DataFrame(result_recorder)\n",
    "fitted_values.columns = X_combined.columns\n",
    "upper_bound = fitted_values.apply(np.quantile, q=0.975, axis=0) #arguments can be passed in like keywords!\n",
    "lower_bound = fitted_values.apply(np.quantile, q=0.025, axis=0)\n",
    "err = fitted_values.apply(np.std, axis=0)\n",
    "pnt_estimates = fitted_values.apply(np.std, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'point_estimate':pnt_estimates, \n",
    "              'standard dev': err, \n",
    "              'upper 95': upper_bound, \n",
    "              'lower 5':lower_bound})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample is a function that literally  does, resample.. not to be confused to with resample method of dataframe. That one is used to handle time series. This one, however, can be used to give non-param bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resample(X_combined, daily_total.values)[0].shape)\n",
    "print(resample(X_combined, daily_total.values)[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
